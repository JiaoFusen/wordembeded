{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing TfIdf Model with MSRPC\n",
    "\n",
    "**Prerequisites:** See the previous notebooks, and generate TfIdf model.\n",
    "\n",
    "## Outline\n",
    "\n",
    "**Main Goal:** To practice the application of Word Embedding models to a real corpus, the MSRPC, made for Paraphrase Recognition task.\n",
    "\n",
    "**Index:**\n",
    "- Loading TfIdf Model generated from Wikipedia dump.\n",
    "- Load MSRPC\n",
    "- Calculate all similarity corpus-distances using tfidf.model for every pair of sentences in MSRP.\n",
    "- Traing a simple machine model to recognize paraphrase using the distance vector model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import TextCorpus, MmCorpus, Dictionary\n",
    "import numpy as np\n",
    "import time\n",
    "from pandas import DataFrame, Series, read_table, read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading tfidf Wiki model\n",
    "corpus_path = '/media/DATA/wiki_es/'\n",
    "tfidf = TfidfModel.load(corpus_path+'wiki-tfidf.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quality</th>\n",
       "      <th>#1 ID</th>\n",
       "      <th>#2 ID</th>\n",
       "      <th>#1 String</th>\n",
       "      <th>#2 String</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>702876</td>\n",
       "      <td>702977</td>\n",
       "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
       "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2108705</td>\n",
       "      <td>2108831</td>\n",
       "      <td>Yucaipa owned Dominick's before selling the ch...</td>\n",
       "      <td>Yucaipa bought Dominick's in 1995 for $693 mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1330381</td>\n",
       "      <td>1330521</td>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10, the ship's owners had published an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3344667</td>\n",
       "      <td>3344648</td>\n",
       "      <td>Around 0335 GMT, Tab shares were up 19 cents, ...</td>\n",
       "      <td>Tab shares jumped 20 cents, or 4.6%, to set a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1236820</td>\n",
       "      <td>1236712</td>\n",
       "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
       "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quality    #1 ID    #2 ID  \\\n",
       "0        1   702876   702977   \n",
       "1        0  2108705  2108831   \n",
       "2        1  1330381  1330521   \n",
       "3        0  3344667  3344648   \n",
       "4        1  1236820  1236712   \n",
       "\n",
       "                                           #1 String  \\\n",
       "0  Amrozi accused his brother, whom he called \"th...   \n",
       "1  Yucaipa owned Dominick's before selling the ch...   \n",
       "2  They had published an advertisement on the Int...   \n",
       "3  Around 0335 GMT, Tab shares were up 19 cents, ...   \n",
       "4  The stock rose $2.11, or about 11 percent, to ...   \n",
       "\n",
       "                                           #2 String  \n",
       "0  Referring to him as only \"the witness\", Amrozi...  \n",
       "1  Yucaipa bought Dominick's in 1995 for $693 mil...  \n",
       "2  On June 10, the ship's owners had published an...  \n",
       "3  Tab shares jumped 20 cents, or 4.6%, to set a ...  \n",
       "4  PG&E Corp. shares jumped $1.63 or 8 percent to...  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_csv('data/msrpc.csv',sep='\\t',header=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5801"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the bow vector of the sentence 1\n",
    "sent = \"Yo como pescado\"\n",
    "vec_sent = dictionary.doc2bow(sent.lower().split())\n",
    "print(vec_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the TFIDF vector of the sentence 1\n",
    "vec_sent_tfidf = tfidf[vec_sent]\n",
    "print(vec_sent_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim TfIdf-Hellinger sentence similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = 'the girl run into the hall'\n",
    "sent2 = 'Here Alice run to the hall'\n",
    "\n",
    "sentence1 = sent1.split()\n",
    "sentence2 = sent2.split()\n",
    "\n",
    "vec_sent1 = dictionary.doc2bow(sentence1)\n",
    "vec_sent2 = dictionary.doc2bow(sentence2)\n",
    "\n",
    "vec_sent1_tfidf = tfidf[vec_sent1]\n",
    "vec_sent2_tfidf = tfidf[vec_sent2]\n",
    "print(vec_sent1_tfidf)\n",
    "print(vec_sent2_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing similarity with Gensim ecuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import kullback_leibler, jaccard, hellinger, cossim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hellinger(vec_sent1_tfidf,vec_sent2_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gensim Cosine:',cossim(vec_sent1_tfidf,vec_sent2_tfidf))\n",
    "print('Gensim Jaccard:',jaccard(vec_sent1_tfidf,vec_sent2_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with Hellinger equation in Gensim is that iterates over the major vector, then in the above example the word 74333(eat) never will affect the result.\n",
    "\n",
    "## Scipy TfIdf-Cosine sentence similarity\n",
    "\n",
    "Testing similarity with Scipy equations. A normalized vector with the above problem is showed to correct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial.distance import jaccard as jaccard_scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine(vec_sent1_tfidf,vec_sent2_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line result in an error because used vectors are bow vectors in the following format: list((wordid,word tfidf)). Then a previous transformation of vectors is needed to 1D numerical vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six import iteritems\n",
    "vec2 = dict(vec_sent1_tfidf)\n",
    "vec1 = dict(vec_sent2_tfidf)\n",
    "#[vec1.get(index, 0.0)**2 for index, value in iteritems(vec2)]\n",
    "nvec1,nvec2 = [],[]\n",
    "words = set(vec1.keys()).union(vec2.keys())\n",
    "for word in words:\n",
    "    nvec1.append(vec1.get(word,0.0))\n",
    "    nvec2.append(vec2.get(word,0.0))\n",
    "print(nvec1,'\\n',nvec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scipy Cosine:',cosine(nvec1,nvec2))\n",
    "print('Scipy Jaccard:',jaccard_scipy(nvec1,nvec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textsim TfIdf-Jaccard sentence similarity\n",
    "\n",
    "Doing similarity with textsim package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/abelm')\n",
    "\n",
    "from textsim.tokendists import jaccard_distance\n",
    "from textsim.tokendists import cosine_similarity_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Textsim Jaccard', jaccard_distance(sent1,sent2))\n",
    "print('TfIdf Textsim Jaccard', jaccard_distance(nvec1,nvec2))\n",
    "#Prerocessed sentences\n",
    "print('Textsim Cosine Sklearn',cosine_similarity_sklearn('girl run hall','Alice eat hall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.asarray(nvec1).reshape((1,-1))\n",
    "B = np.asarray(nvec2).reshape((1,-1))\n",
    "\n",
    "print('TfIdf Textsim Cosine Sklearn',cosine_similarity_sklearn(A,B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn TfIdf-Cosine sentence similarity\n",
    "\n",
    "The last experiment is made with TfIdf matrix from gensim.\n",
    "Unfortunately to load the Wikipedia dump to make a tf-idf index is to much for this computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from textsim.tokendists import cosine_similarity_sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Sklearn cosine for raw sentences implemented in textsim\n",
    "cosine_similarity_sklearn(sent1,sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.asarray(nvec1).reshape((1,-1))\n",
    "B = np.asarray(nvec2).reshape((1,-1))\n",
    "cosine_similarity(A,B)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "* 0.659 input = bowvec, Hellinger, Gensim, \n",
    "* 0.267 input = bowvec, Cosine, Gensim\n",
    "* 0.839 input = bowvec, Jaccard, Gensim\n",
    "* 0.732 input = tfidf vec, Cosine, Scipy\n",
    "* 1.000 input = tfidf vec, Jaccard, Scipy\n",
    "* 0.777 input = str, Jaccard, Textsim, stopwords_filter=no\n",
    "* 0.800 input = str, Jaccard, Textsim, stopwords_filter=yes\n",
    "* 0.333 input = str, Cosine, Textsim-sklearn, stopwords_filter=yes\n",
    "* 0.433 input = str, Cosine, Textsim-sklearn, stopwords_filter=no\n",
    "* 0.267 input = tfidf vec, Cosine, Sklearn\n",
    "\n",
    "As you can self analyze Gensim and Sklearn cosine have the same result. The sentences have words in common and in the context of \"Alice's Adventures in Wonderland\" by Lewis Carroll have the same mining, this book is part of the Gutenberg collection but only appears on Wikipedia dump as articles of few importance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
